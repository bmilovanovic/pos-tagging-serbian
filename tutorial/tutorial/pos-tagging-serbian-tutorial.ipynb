{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Kreiranje tagera za srpski jezik pomoću NLTK alata</h1>\n",
    "\n",
    "U 2019. godini objavljeni su značajni radovi u oblasti obrade prirodnih jezika. Na osnovu jezičkog modela BERT čiji je tvorac kompanija Google, napravljene su varijante poput DistilBERT, RoBERTa, AlBERT, XLNet i drugi, koji dostižu visoke rezultate u raznim zadacima obrade prirodnog jezika. Primjene su sve šire, algoritmi kompleksniji. Ispod ovog visoko apstraktnog nivoa, može se naći ograničen skup zadataka koji i dalje predstavljaju izazov za istraživače. Mala poboljšanja u osnovnim zadacima poput tagiranja direktno i višestruko utiču na zadatke koji stoje kasnije u sekvenci obrade (eng. pipeline)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tagiranje</h2>\n",
    "\n",
    "Tagiranje (ili etiketiranje) je proces dodjele oznake (tag, etiketa) svakom tokenu u određenom tekstu. Prema tipu taga koji se dodjeljuje, tagiranje može imati razne primjene. U osnovnoj varijanti, tagiranje podrazumijeva određivanje vrste riječi u rečenici (eng. POS tagging). \n",
    "\n",
    "Program koji vrši tagiranje naziva se tager. Ovakvi programi mogu biti kreirani na brojne načine, a u ovom radu će biti govoreno o primjeni NLTK alata u kreiranju tagera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Automatsko tagiranje pomoću NLTK platforme</h3>\n",
    "\n",
    "NLTK je biblioteka napisana u programskom jeziku Pajton. Pored toga što sadrži više od 50 korpusa i jezičkih resursa, koristi se za pravljenje programa za rad nad podacima generisanim ljudskim jezikom. Ovakvi programi imaju primjene u klasifikaciji, tokenizaciji, stemovanju, tagiranju, parsiranju i semantičkom odlučivanju.\n",
    "\n",
    "Automatsko tagiranje podrazumijeva dodjelu taga svakom tokenu u nepoznatom tekstu jednostavnim pokretanjem tagera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Today', 'NOUN'),\n",
       " ('we', 'PRON'),\n",
       " (\"'re\", 'VERB'),\n",
       " ('going', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('build', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('tagger', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('Serbian', 'ADJ'),\n",
       " ('language', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "text = nltk.word_tokenize(\"Today we're going to build a tagger for Serbian language.\")\n",
    "nltk.pos_tag(text, tagset=\"universal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svakom tokenu je ispravno dodjeljena vrsta riječi osim u slučaju \"today\" (prilog). Ovo je zapravo jedan od rijetkih slučajeva da je podrazumijevani tager pogriješio. Pogledajmo kako ovaj tager radi na sprskom jeziku:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Možeš', 'NOUN'),\n",
       " ('li', 'VERB'),\n",
       " ('da', 'NOUN'),\n",
       " ('pogodiš', 'NOUN'),\n",
       " ('vrstu', 'NOUN'),\n",
       " ('riječi', 'NOUN'),\n",
       " ('u', 'ADJ'),\n",
       " ('rečenici', 'NOUN'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.word_tokenize(\"Možeš li da pogodiš vrstu riječi u rečenici?\")\n",
    "nltk.pos_tag(text, tagset=\"universal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primjećuje se da je tager u skoro svim slučajevima pogriješio. Ugrađeni tager nije primjenljiv na srpski jezik. U narednim koracima donijećemo postupnu implementaciju tagera za srpski jezik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Učitavanje podataka</h3>\n",
    "\n",
    "Da bi se uopšte sproveo proces tagiranja, neophodno je da se izvrši proces tokenizacije, tj. da se ulazni tekst podijeli na tokene. Ovaj proces nije trivijalan te se njime nećemo baviti u ovom radu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "input_data = Path('tagged-data-original.txt').read_text(encoding=\"utf-8-sig\").strip().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1\\tJaroslav\\tN:m\\tPROPN\\tJaroslav',\n",
       " '1\\tHašek\\tN:m\\tPROPN\\tHašek',\n",
       " '1\\t:\\tPUNCT\\tPUNCT\\t:',\n",
       " '1\\tDOŽIVLJAJI\\tN:m\\tNOUN\\tdoživljaj']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jaroslav', 'N:m'), ('Hašek', 'N:m'), (':', 'PUNCT'), ('DOŽIVLJAJI', 'N:m')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tagged_tokens = [(tt.split()[1], tt.split()[2]) for tt in input_data]\n",
    "input_tagged_tokens[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jaroslav', 'Hašek', ':', 'DOŽIVLJAJI']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens = [token for (token, tag) in input_tagged_tokens]\n",
    "input_tokens[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199646"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31139"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique tokens\n",
    "len(list(set(input_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Učitali smo tekst podijeljen na tokene i njihove tagove. Međutim, za stvaranje tagera, potrebno je izvršiti podjelu na rečenice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10890"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tagged_sents = []\n",
    "last_sentence = []\n",
    "\n",
    "last_sentence_number = 1\n",
    "for idx in range(len(input_data)):  # iterate through every word\n",
    "    parts = input_data[idx].split()\n",
    "    sentence_number = int(parts[0]) # 1\n",
    "    token = parts[1] # Jaroslav\n",
    "    tag = parts[2] # PROPN\n",
    "  \n",
    "    if sentence_number != last_sentence_number:        # if this is the end of the sentence, finalize it and build a new one\n",
    "        last_sentence_number = sentence_number\n",
    "        input_tagged_sents.append(last_sentence)\n",
    "        last_sentence = []    \n",
    "\n",
    "    last_sentence.append((token, tag)) # always add the current token to the last sentence\n",
    "\n",
    "# add the last sentence\n",
    "input_tagged_sents.append(last_sentence)\n",
    "\n",
    "len(input_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Jaroslav', 'N:m'), ('Hašek', 'N:m'), (':', 'PUNCT'), ('DOŽIVLJAJI', 'N:m'), ('DOBROG', 'A:am'), ('VOJNIKA', 'N:m'), ('ŠVEJKA', 'N:m'), ('u', 'PREP'), ('prvom', 'A:an'), ('svetskom', 'A:an'), ('ratu', 'N:m'), (';', 'SENT')], [('preveo', 'V:m'), ('STANISLAV', 'N:m'), ('VINAVER', 'N:m'), ('Veliko', 'A:an'), ('doba', 'N:n'), ('traži', 'V'), ('velike', 'A:af'), ('ljude', 'N:m'), ('.', 'SENT')]]\n"
     ]
    }
   ],
   "source": [
    "print(input_tagged_sents[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sada je dobijen tekst podijeljen na rečenice te se može nastaviti sa daljom obradom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Analiziranje podataka</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('V', 24260), ('PUNCT', 20911), ('N:m', 19776), ('N:f', 19295), ('PREP', 16542), ('CONJ', 15677), ('PRO', 13842), ('SENT', 10566), ('ADV', 8980), ('A:am', 8184), ('PAR', 7996), ('N:n', 7361), ('A:af', 6305), ('V:m', 5278), ('NUM', 3583), ('A:an', 3506), ('V:f', 2459), ('V:n', 2179), ('ABB', 641), ('N', 485), ('A:bm', 270), ('A:bf', 229), ('X', 224), ('PRO:f', 203), ('PRO:m', 190), ('A:cm', 116), ('INT', 110), ('A', 109), ('PRO:n', 106), ('A:cf', 81), ('A:bn', 73), ('A:cn', 33), ('NUM:m', 29), ('NUM:f', 17), ('A:f', 6), ('PREF', 4), ('A:m', 4), ('N:af', 3), ('NUM:n', 3), ('PRO:an', 2), ('A:n', 2), ('PRO:af', 2), ('PRO:am', 1), ('N:an', 1), ('A:asm', 1), ('A:a', 1)]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "tag_fd = nltk.FreqDist(tag for (token, tag) in input_tagged_tokens)\n",
    "print(tag_fd.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najviše tokena je iz grupe imenica, zatim znakova interpunkcije i glagola. Zapravo, prvih 5 vrsta riječi (već navedene + pridjevi i predlozi) predstavlja 60% svih tagova, što se može vidjeti sa sledećeg dijagrama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x215023577b8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_fd.plot(cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Implementacija tagera</h3>\n",
    "\n",
    "U ovoj sekciji će biti data implementacija različitih tagera, a onda će se njihovim kombinovanjem dobiti tager od kojeg najviše očekujemo.\n",
    "\n",
    "Prije toga, neophodno je podijeliti podatke na skup za treniranje i skup za testiranje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8712\n"
     ]
    }
   ],
   "source": [
    "size = int(len(input_tagged_sents) * 0.8)\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(input_tagged_sents)\n",
    "train_sents = input_tagged_sents[:size]\n",
    "test_sents = input_tagged_sents[size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Podrazumijevani tager (eng. Default tagger)</h4>\n",
    "\n",
    "Ovaj tager je najjednostavniji, ali može da obradi svaku riječ. Ideja koja stoji iza ovog tagera je da je, pošto najviše ima imenica, svaka riječ najvjerovatnije i jesta imenica. Tako i radi - svakoj riječi dodjeljuje tag 'imenica'.\n",
    "Ovaj tager se ne koristi zasebno, već kao podrška naprednijim tagerima koji ne tagiraju svaku riječ.\n",
    "Može se reći da, nakon što se iscrpi poznati skup riječi nekog jezika, nove riječi koje budu dolazile su vjerovatno imenice, tako da ovaj tager doprinosi robusnosti sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_most_frequent = tag_fd.most_common()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Svaka', 'V'),\n",
       " ('riječ', 'V'),\n",
       " ('će', 'V'),\n",
       " ('dobiti', 'V'),\n",
       " ('isti', 'V'),\n",
       " ('tag', 'V')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_tagger = nltk.DefaultTagger(pos_tag_most_frequent)\n",
    "\n",
    "tokens = nltk.word_tokenize(\"Svaka riječ će dobiti isti tag\")\n",
    "default_tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svi tageri imaju veoma korisnu metodu evaluate() koja testira dobijeni tager na već tagiranom skupu riječi i vraća preciznost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12151508169459944"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_tagger.evaluate(input_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I sa ovako trivijalnim tagerom, uspješno je pogođen svaki peti token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Tager regularnim izrazima (eng. RegExp tagger)</h4>\n",
    "\n",
    "Ideja koja se nadograđuje na tu da svakoj riječi dodijelimo isti token jeste da primjenimo grupu pravila koja će na osnovu oblika riječi donijeti odluku. Jedan takav, veoma ograničeni skup, dat je iznad. Sastoji se iz pravila kao što su: ako se riječ završava na \"ki\", onda je to pridjev, ako je na \"ti\" ili \"ći\", onda je to glagol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "...     (r'.*ki$', 'A'),\n",
    "...     (r'.*ti$', 'V'),\n",
    "...     (r'.*ći$', 'V'),\n",
    "...     (r'^-?[0-9]+(\\.[0-9]+)?$', 'NUM'),   # cardinal numbers\n",
    "...     (r'.*', 'V')                      # nouns (default)\n",
    "... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13063622612023282"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "regexp_tagger.evaluate(input_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sa ovim skupom pravila, uspješnost tagiranja se povećala u odnosu na podrazumijevani tager, ali samo za 2 procenta. Sa boljim skupom pravila tačnost bi bila veća ali samo do određene granice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Tager prepoznavanjem (eng. Lookup tagger)</h4>\n",
    "\n",
    "Većina riječi koja se često pojavljuje nisu imenice. Potražićemo 100 riječi koje se najčešće pojavljuju i zapamtiti njihov najčešći tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43305651002274026"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = nltk.FreqDist(input_tokens)\n",
    "cfd = nltk.ConditionalFreqDist(input_tagged_tokens)\n",
    "most_freq_tokens = fd.most_common(100)\n",
    "likely_tags = dict((token,cfd[token].max()) for (token,_) in most_freq_tokens)\n",
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags)\n",
    "baseline_tagger.evaluate(input_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sa samo 100 memorisanih riječi i njihovih tagova, ovaj tager je uspio da pogodi skoro svaki drugi tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Danas', None),\n",
       " ('je', 'AUX'),\n",
       " ('lijep', None),\n",
       " ('i', 'CCONJ'),\n",
       " ('sunčan', None),\n",
       " ('dan', None)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.word_tokenize(\"Danas je lijep i sunčan dan\")\n",
    "baseline_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na nepoznatom tekstu, većina tagova su dodijeljeni kao \"None\" jer nije prepoznao riječi među odabranih 100. Moguće je da ove tokene prosledimo podrazumijevanom tageru koji će znati da ih obradi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6373130440880358"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags, backoff=nltk.DefaultTagger(pos_tag_noun))\n",
    "baseline_tagger.evaluate(input_tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(cfd, tokenlist):\n",
    "    lt = dict((token, cfd[token].max()) for token in tokenlist)\n",
    "    baseline_tagger = nltk.UnigramTagger(model=lt, backoff=nltk.DefaultTagger(pos_tag_noun))\n",
    "    return baseline_tagger.evaluate(input_tagged_sents)\n",
    "\n",
    "def display():\n",
    "    import pylab\n",
    "    token_freqs = nltk.FreqDist(input_tokens).most_common()\n",
    "    tokens_by_freq = [w for (w, _) in token_freqs]\n",
    "    cfd = nltk.ConditionalFreqDist(input_tagged_tokens)\n",
    "    sizes = 2 ** pylab.arange(15)\n",
    "    perfs = [performance(cfd, tokens_by_freq[:size]) for size in sizes]\n",
    "    pylab.plot(sizes, perfs, '-bo')\n",
    "    # pylab.title('Performanse tagera prepoznavanjem u odnosu na model promjenljive veličine')\n",
    "    pylab.xlabel('Number of the stored tags')\n",
    "    pylab.ylabel('Accuracy')\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Unigram tager</h4>\n",
    "\n",
    "Ako se tager prepoznavanjem proširi da obuhvata sve riječi i ako se proces pronalaženja najčešćih riječi i njihovih najvjerovatnijih tagova zamijeni treniranjem, dobiće se Unigram tager. Dakle, zasnovan je na jednostavnom statističkom algoritmu: za svaku riječ predložiće njen najvjerovatniji tag, iako ta riječ može imati više tagova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8678468404053354"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger = nltk.UnigramTagger(train_sents)\n",
    "unigram_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram tager očekivano daje bolje rezultate od tagera prepoznavanjem, ali i dalje analizira riječ po riječ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>N-gram tager</h4>\n",
    "\n",
    "Uopštavanjem Unigram tagera gdje se analizira i kontekst riječi, a ne samo ta riječ dobija se N-gram tager. U zavisnosti od broja riječi koje prethode riječi za koju se traži tag, dobijamo Bigram, Trigram tagere itd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Danas', 'ADV'),\n",
       " ('je', 'AUX'),\n",
       " ('lijep', None),\n",
       " ('i', None),\n",
       " ('sunčan', None),\n",
       " ('dan', None),\n",
       " ('.', None)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = nltk.BigramTagger(train_sents)\n",
    "t2.tag(nltk.word_tokenize(\"Danas je lijep i sunčan dan.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prve dvije riječi su korektno tagirane. Međutim, za ostatak riječi tager nije mogao da nađe kombinacije u trening skupu pa ih je zato označio kao 'None'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Kombinovani tager</h4>\n",
    "\n",
    "N-gram tageri nisu uspješni u svim situacijama, te je potrebno pozvati u pomoć tagere koji znaju da rade nad manjim, neviđenim sekvencama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t0:  0.21400922113464335\n",
      "t1:  0.9031287753642842\n",
      "t2:  0.9050518997016692\n",
      "t3:  0.9051505214625607\n"
     ]
    }
   ],
   "source": [
    "t0 = nltk.DefaultTagger(pos_tag_noun)\n",
    "print(\"t0: \", t0.evaluate(test_sents))\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "print(\"t1: \", t1.evaluate(test_sents))\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "print(\"t2: \", t2.evaluate(test_sents))\n",
    "t3 = nltk.TrigramTagger(train_sents, backoff=t2)\n",
    "print(\"t3: \", t3.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Može se primjetiti da je dodavanjem Bigram i Trigram tagera čak došlo do smanjenja ukupne tačnosti. To obrazlažemo time što u srpskom jeziku red riječi nije striktno određen. Moguće je da bi ovaj tager doprinio više pri većem trening skupu.\n",
    "\n",
    "<h4>Afiksni tager</h4>\n",
    "\n",
    "Od sekvencijalnih tagera u NLTK alatu postoji još i afiksni tager. Ovaj tager određuje tag tokena prema prefiksu ili sufikse fiksne, konfigurabilne dužine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8845632288764516"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at = nltk.AffixTagger(train_sents, backoff=t1)\n",
    "at.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postoje i nestandardni tageri, koji su vremenom ugrađivani pod uticajem eskternih saradnika, u zasebne potpakete.\n",
    "\n",
    "<h4>CRF tager</h4>\n",
    "\n",
    "Ovaj tager se zasniva na uslovnim nasumičnim poljima (eng. [Conditional Random Fields](https://en.wikipedia.org/wiki/Conditional_random_field))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9334549668384329"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crft = nltk.tag.CRFTagger()\n",
    "crft.train(train_sents,'model.crf.tagger')\n",
    "\n",
    "crft.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>HMM tager</h4>\n",
    "\n",
    "Ovaj tager se zasniva na skrivenim Markovljevim modelima (eng. [Hidden Markov Models](https://sr.wikipedia.org/wiki/Skriveni_Markovljev_model)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47760053255750884"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmmt = nltk.tag.hmm.HiddenMarkovModelTrainer().train_supervised(train_sents)\n",
    "\n",
    "hmmt.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Perceptron tager</h4>\n",
    "\n",
    "Ovaj tager se zasniva na uprosječenoj jednoslojnoj neuralnoj mreži."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9499248009073202"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = nltk.tag.perceptron.PerceptronTagger(load=False)\n",
    "pt.train(train_sents)\n",
    "\n",
    "pt.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>TnT tager</h4>\n",
    "\n",
    "TnT je skraćenica od engleske riječi *Trigrams'n'Tags* i predstavlja statistički tager zasnovan na drugorazrednim Markovljevim modelima. Optimizovan je za brzinu rada. Više se može naći u [originalnoj implementaciji](http://www.coli.uni-saarland.de/~thorsten/tnt/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9055450085061268"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tntt = nltk.tag.tnt.TnT(unk=t1, Trained=True)\n",
    "tntt.train(train_sents)\n",
    "\n",
    "tntt.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Brilov tager</h4>\n",
    "\n",
    "Brilovi tageri polaze od datog tagera te na osnovu odabranog skupa pravila transformišu incijalno zadate tokene. Postoji više predefinisanih skupova pravila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brill24 \n",
      "    Return 24 templates of the seminal TBL paper, Brill (1995)\n",
      "     \n",
      "\n",
      "fntbl37 \n",
      "    Return 37 templates taken from the postagging task of the\n",
      "    fntbl distribution http://www.cs.jhu.edu/~rflorian/fntbl/\n",
      "    (37 is after excluding a handful which do not condition on Pos[0];\n",
      "    fntbl can do that but the current nltk implementation cannot.)\n",
      "     \n",
      "\n",
      "nltkdemo18 \n",
      "    Return 18 templates, from the original nltk demo, in multi-feature syntax\n",
      "     \n",
      "\n",
      "nltkdemo18plus \n",
      "    Return 18 templates, from the original nltk demo, and additionally a few\n",
      "    multi-feature ones (the motivation is easy comparison with nltkdemo18)\n",
      "     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk.tag.brill.describe_template_sets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sortirani po performansama, od najboljeg do najlošijeg skupa pravila, pokazali su se: brill24, fntbl37, nltkdemo18plus, nltkdemo18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRILL + DEFAULT:  0.6800710076678419\n",
      "BRILL + UNIGRAM:  0.9064079489139278\n",
      "BRILL + BIGRAM:  0.905939495549693\n"
     ]
    }
   ],
   "source": [
    "bt0 = nltk.tag.brill_trainer.BrillTaggerTrainer(t0, nltk.tag.brill.brill24()).train(train_sents)\n",
    "print(\"BRILL + DEFAULT: \", bt0.evaluate(test_sents))\n",
    "bt1 = nltk.tag.brill_trainer.BrillTaggerTrainer(t1, nltk.tag.brill.brill24()).train(train_sents)\n",
    "print(\"BRILL + UNIGRAM: \", bt1.evaluate(test_sents))\n",
    "bt2 = nltk.tag.brill_trainer.BrillTaggerTrainer(t2, nltk.tag.brill.brill24()).train(train_sents)\n",
    "print(\"BRILL + BIGRAM: \", bt2.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Varijante Brilovog tagera nad ostalim tagerima</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brill + CRF:  0.9376710471165463\n"
     ]
    }
   ],
   "source": [
    "bcrft = nltk.tag.brill_trainer.BrillTaggerTrainer(crft, nltk.tag.brill.brill24()).train(train_sents)\n",
    "print(\"Brill + CRF: \", bcrft.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brill + HMM:  0.4788086491284302\n"
     ]
    }
   ],
   "source": [
    "bhmmt = nltk.tag.brill_trainer.BrillTaggerTrainer(hmmt, nltk.tag.brill.brill24()).train(train_sents)\n",
    "print(\"Brill + HMM: \", bhmmt.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRILL + PERCEPTRON:  0.9501220444291033\n"
     ]
    }
   ],
   "source": [
    "bpt = nltk.tag.brill_trainer.BrillTaggerTrainer(pt, nltk.tag.brill.brill24()).train(train_sents)\n",
    "print(\"BRILL + PERCEPTRON: \", bpt.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#btntt = nltk.tag.brill_trainer.BrillTaggerTrainer(tntt, nltk.tag.brill.brill24()).train(train_sents)\n",
    "#print(\"BRILL + TNT: \", btntt.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRILL + AFFIX:  0.9066791587563796\n"
     ]
    }
   ],
   "source": [
    "bat = nltk.tag.brill_trainer.BrillTaggerTrainer(at, nltk.tag.brill.brill24()).train(train_sents)\n",
    "print(\"BRILL + AFFIX: \", bat.evaluate(test_sents)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Čuvanje tagera</h3>\n",
    "\n",
    "Treniranje na većim korpusima može zahtijevati značajne resurse, te je korisno rezultate čuvati za sledeću upotrebu. Standard za ovu upotrebu u jeziku Pajton je biblioteka \"Pickle\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "output = open('t2.pkl','wb')\n",
    "dump(t2, output, -1)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovaj objekat se kasnije može učitati i ponovno koristiti za tagiranje, npr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "input = open('t2.pkl','rb')\n",
    "t2 = load(input)\n",
    "input.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Danas', 'ADV'),\n",
       " ('je', 'AUX'),\n",
       " ('lijep', 'NOUN'),\n",
       " ('i', 'CCONJ'),\n",
       " ('sunčan', 'NOUN'),\n",
       " ('dan', 'NOUN')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.word_tokenize(\"Danas je lijep i sunčan dan\")\n",
    "t2.tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
